---
title: 'Glossary of Biases'
author: 'Chiawei Wang'
date: 'October 2023'
date-format: 'MMMM YYYY'
---

`This document provides a glossary of biases.`

# What is Bias?

Bias means having unfair feelings or thoughts about something or someone. It can be because we don't like or trust them, even without a good reason. Bias can also happen in science when mistakes are made that affect the results. It's important to be fair and accurate.

# Cognitive Biases

Cognitive bias is when our thinking goes off track, leading to mistakes or illogical judgments. It happens because we see the world based on our own perspective, which can influence our actions. These biases can cause us to see things wrongly or make decisions that don't make sense. Some biases can be helpful in specific situations, while others result from our limits in processing information.

## Belief

- **Anchoring bias** is when people rely too much on the first piece of information they hear. This can happen in many situations, like when you're buying a car. If the seller starts with a high price, you might think that's what it's worth. But if they start with a low price, you might think that's the value. This bias can affect your decisions and make you spend more money than you should.
    - **Common source bias** is a problem in research when we get information about both the things we're studying and the people we're studying from the same group. This can happen in surveys, experiments, and studies. It's a big worry because it can make our results not trustworthy. It's especially common in public administration research, where it can lead to wrong conclusions about how well an organisation is doing.
    - **Conservatism bias** is when people don't change their beliefs enough when they get new information. Instead of updating their beliefs fully, they tend to stick too closely to their old ideas. It's like they don't adjust their views as much as they should based on the new evidence they receive. This bias makes them slow to change their minds compared to what they would do if they used Bayes' theorem, a mathematical method for updating beliefs.
    - **Functional fixedness** is when you're stuck thinking an object can only be used in its usual way, even if it could solve a problem differently. For example, thinking a hammer is only for nails, not realising it can hold down papers like a paperweight. Children are less affected, but as they grow, they tend to see objects as having one fixed use.
    - **Law of the instrument** is a cognitive bias where people rely too much on a tool they know well. It's like if you only have a hammer, you might start thinking everything is a nail. This idea was mentioned by Abraham Maslow in 1966, but it's not clear if he came up with the hammer and nail example. It's a warning against using the same solution for everything.
- **Availability bias**, is a mental shortcut where we rely on the first examples that come to mind when thinking about something. We tend to think that if we can easily remember it, it must be important. This shortcut is biased towards recent information. If we can quickly remember the results of something, we often think those results are more significant. We use this shortcut when we don't doubt the accuracy of our memory.
    - **Anthropocentrism** means seeing humans as the most important thing in the universe. It's like thinking everything exists mainly for humans to use. This idea often separates humans from nature and makes them think they're better than everything else, like animals and plants. It's a big topic in discussions about how humans treat the environment. Some say it's causing problems, while others think it's necessary to make the world suitable for humans.
    - **Attentional bias** means that what we pay attention to can affect how we see things. It can make us ignore other options when we're focused on something. For instance, smokers might notice smoking-related things more because their brain likes it. It can also relate to problems like anxiety and depression.
    - **Frequency illusion**, also known as the **Baader-Meinhof phenomenon**, is when you start noticing something more often after seeing it for the first time. It makes you think that thing is happening more frequently than before. For example, you might hear a song once and then suddenly hear it everywhere. The term Baader-Meinhof phenomenon came from a person's experience, and it's like when you learn a new word and then see it in many places.
    - **Implicit bias** or **stereotype** is when we unconsciously link certain traits to people from different social groups without realising it. These biases come from our experiences and associations with things like race or gender. They impact how we view and treat others, even if we don't realise we have these biases. Unlike explicit stereotypes that we consciously think about, implicit biases happen automatically and can still affect us even if we don't want them to.
    - **Salience bias** is when our brains naturally pay more attention to things that stand out, like bright colours or emotional experiences, rather than things that are ordinary. This can affect how we make decisions because we tend to give more importance to the noticeable stuff. So, it's a bias that leans towards what's more striking or prominent.
    - **Well-travelled road effect** is when people perceive familiar routes as quicker to travel, affecting their time estimations. This can lead to errors when choosing routes to unfamiliar places. It's most evident when driving but applies to pedestrians and public transport users too. This phenomenon was scientifically studied in the 1980s and 1990s. It's akin to underestimating time on familiar routes because our brains are less engaged, influencing our perception of learning and experience.
- **Apophenia** or **pattern recognition bias** is when people see patterns or connections in random or meaningless data. This can happen in many situations, like when people think they see a face in a cloud or hear hidden messages in music. It's a type of illusion that can lead to false beliefs and superstitions. It's also linked to pareidolia, where people see faces in things like clouds or toast.
    - **Clustering illusion** is when we mistakenly think that random events happening close together are not random. This happens because we tend to underestimate how much variation can occur in small samples of random data. For example, people might see patterns in stock market changes or clusters of bomb impacts on a map during World War II. But often, these patterns are just coincidences, and a closer look shows that they are actually random.
    - **Illusory correlation** means people sometimes see a connection between things when there isn't one. This happens because unusual or new things grab our attention. It's how stereotypes can develop and last. For example, if someone thinks a certain group always acts a certain way, they might believe it happens more often than it actually does. These stereotypes can stick around even if there's no real interaction between the person and the group they're stereotyping.
- **Cognitive dissonance** is when our beliefs, actions, or ideas clash and make us feel stressed. We try to make them match to feel better. For example, if we do something that goes against our values, we might change our beliefs or avoid things that remind us of the clash. This idea comes from psychologist Leon Festinger. He said we want our thoughts to make sense, and when they don't, we feel uncomfortable and try to fix it, sometimes by just believing what we want to.
    - **Normalcy bias** is when people underestimate the danger of disasters or threats, thinking they won't happen to them. This bias can make people unprepared for things like natural disasters or financial crashes. It affects many people during such events. It's the opposite of overreacting to small changes, which is also a bias.
    - **Effort justification** is when you think something is more valuable just because you worked hard for it.
    - **Ben Franklin effect** is when you start to like someone more after you've done them a favour. It happens because your mind tries to make sense of your actions by convincing you that you must like the person if you help them.
- **Confirmation bias** is our tendency to favour information that aligns with our existing beliefs, ignoring conflicting evidence. It stems from a desire for our beliefs to be validated, leading to stubbornly holding incorrect ideas, over-relying on initial information, and imagining connections that don't exist. Critical thinking can mitigate it, but it remains prevalent in politics, organisations, finance, and science, fostering unwavering convictions and disregarding opposing evidence. Social media compounds this issue by reinforcing existing beliefs and filtering out dissenting opinions.
    - **Belief perseverance** is when people cling to their beliefs despite strong contrary evidence, sometimes strengthening their convictions, also known as the **backfire effect**. Reassuring someone about vaccine safety can make them more convinced of danger, making myths familiar and challenging their worldviews. Strategies like presenting facts and alternatives can correct false beliefs. Recent research indicates backfire effects may be less common than believed.
    - **Congruence bias** is when people rely too much on testing their first idea and forget to test other possibilities. They often try to confirm their initial belief instead of trying to disprove it, which is similar to confirmation bias.
    - **Selective perception** is when we tend to ignore and forget things that make us uncomfortable or go against our beliefs. For example, a teacher might have a favourite student and overlook their poor performance while also failing to notice the progress of their least favourite student.
    - **Semmelweis reflex**, named after Ignaz Semmelweis, is the tendency to reject new evidence contradicting established beliefs. Semmelweis found hand disinfection reduced childbed fever deaths in the 19th century, but doctors resisted it as they couldn't believe clean hands transmitted disease. It illustrates how people often resist new facts challenging prevailing norms and beliefs, even when evidence is clear.
- **Egocentric bias** is when people have an inflated view of themselves because they favour ideas aligning with their perspective, making them remember such ideas better. It was first identified in 1979 by Michael Ross and Fiore Sicoly and encompasses several related biases. Its impact varies by factors like age and language skills, studied through questionnaires on personal experiences or hypothetical scenarios in group tasks, mental health, and voting patterns.
    - **Bias blind spot** is when people notice biases in others but not in themselves. It's like having a blind spot in your vision. Many people think they're less biased than others, and only a few think they're more biased. This bias blind spot varies between people, and those who strongly believe in personal free will tend to have it more. It's a stable trait and doesn't affect decision-making abilities. People still think they're less biased regardless of their actual skills.
    - **False consensus effect** is when people believe that their own choices and judgments are typical, assuming others share their views. This can boost self-confidence and is often driven by a desire to fit in socially. It doesn't have a single cause but can result from various factors, including the availability of information. Researchers have observed it widely and found it even in professional decision-making contexts.
    - **False-uniqueness effect** is when people wrongly believe their qualities are unique, often measured by comparing self-estimates with peer-reported data. For instance, people may think they excel in certain traits or would behave differently in specific situations. It contrasts with the false consensus effect, which overestimates trait commonality, and both relate to self-esteem.
    - **Barnum effect**, also known as the **Forer effect**, is when people believe general personality descriptions uniquely apply to them, although they could fit many. It explains the acceptance of paranormal beliefs like astrology, often exploited by practitioners to create a sense of special abilities. People tend to trust such assessments when presented by authority figures. Bertram Forer called it the fallacy of personal validation, and Paul Meehl linked it to P T Barnum's style.
    - **Illusion of asymmetric insight** is when people think they understand others better than others understand them. This happens because they tend to see their quick responses to questions as less revealing, while they find others' responses more meaningful.
    - **Illusion of control** is when people think they have more control over events than they actually do. It was coined by psychologist Ellen Langer and can affect things like gambling behaviour and belief in the paranormal. It's one of the positive illusions, along with illusory superiority and optimism bias.
    - **Illusion of transparency** is when people think others can understand their thoughts and feelings more than they actually can. It's like assuming that others can read your mind. This bias is similar to the illusion of asymmetric insight, where people believe they understand others better than others understand them.
    - **Illusion of validity** is when people overly trust their predictions based on data that seems to fit their expectations, even when they know the predictions may not be very accurate. It's like believing someone is a librarian just because their personality matches the librarian stereotype, without considering the limitations in the information used for the prediction.
    - **Illusory superiority** is when someone overestimates their abilities compared to others. Also known as the **above-average effect** or **Dunning-Kruger effect**, it depends on culture, with East Asians tending to underestimate their skills for social harmony. This phenomenon was named in 1991 by Van Yperen and Buunk.
    - **Naïve cynicism** is when people mistakenly believe others are more self-centred than they really are. Coined by Justin Kruger and Thomas Gilovich, it's been studied in various situations, including negotiations, group membership, marriage, economics, and government policy.
    - **Naïve realism** is our tendency to think we see the world objectively and view those who disagree as uninformed or biased. This belief underlies cognitive biases like the false consensus effect and fundamental attribution error. Coined by Lee Ross in the 1990s, it challenges the idea that our senses provide unbiased perceptions and is a foundational concept in social psychology.
    - **Overconfidence effect** is when people overestimate their abilities and express unwarranted certainty in their beliefs. Confidence often exceeds accuracy, notably for challenging questions on unfamiliar topics. For example, in spelling, people claimed 100% certainty but were correct only 80% of the time, revealing a 20% error rate.
    - **Planning fallacy** is when people optimistically underestimate how long tasks will take, even if past similar tasks took longer. This bias affects personal predictions but leads to pessimistic estimates when made by others. Daniel Kahneman and Amos Tversky introduced the concept in 1979, and it can result in time, cost, and benefit misjudgments.
    - **Restraint bias** is when people think they can control their impulses better than they actually can, which can lead to more impulsiveness and temptations, affecting addiction. It happens because they believe they have strong self-control even when they don't. This can be influenced by various visceral impulses like hunger, sexual arousal, or fatigue, which signal the body's current state and needs.
    - **Trait ascription bias** is the tendency for people to view themselves as having variable personalities and behaviours while seeing others as more predictable. It happens because we can easily observe our own internal states but not those of others. This bias contributes to stereotypes and prejudice. However, the concept of personality traits is debated in psychology and social science.
    - **Third-person effect** is when people think that media messages have a bigger impact on others than on themselves due to personal biases. It happens because they want to feel less influenced, distancing themselves from those who might be affected, and believing others are influenced by the messages. This effect is also seen in social media and websites.
- **Extension neglect** is when people ignore the sample size in a study but still make conclusions about a larger population based on it. This can lead to invalid results, especially with small sample sizes. Often, articles don't emphasise sample size, causing readers to overlook its importance and trust the conclusions.
    - **Base rate fallacy** is when people ignore general statistics and focus on specific details. It's a type of extension neglect. In legal contexts, it's known as the **prosecutor's fallacy** or **defence attorney's fallacy** when applied to statistical test results like DNA tests. It was named by William C. Thompson and Edward Schumann in 1987.
    - **Compassion fade** is the tendency to feel less empathy as the number of people in need increases. It affects prosocial behaviour and was coined by psychologist Paul Slovic. This phenomenon is evident when people hesitate to help during mass crises. It's linked to the concept of compassion collapse, where people turn away from mass suffering. This effect is driven by cognitive biases like the affect heuristic, which makes decisions based on emotional attachments, and others like the identifiable victim effect and pseudo-inefficacy.
    - **Conjunction fallacy**, also called the **Linda problem**, is when people believe that a combination of two or more things is more likely than any single thing alone, even though this goes against the rules of probability. It's a formal fallacy.
    - **Duration neglect** is when people's judgments about how unpleasant a painful experience was don't really consider how long it lasted. Instead, they focus on the most painful part (the peak) and how quickly the pain goes away. This is called the peak-end rule. It's a type of extension neglect.
    - **Hyperbolic discounting**, a key concept in behavioural economics, explains how people value rewards over time. It suggests that we tend to prefer smaller immediate rewards over larger delayed ones, with our preference changing more rapidly for short delays and more slowly for longer ones. This leads to inconsistent choices and a bias towards immediate rewards despite knowing better. It contrasts with the constant discounting assumed in traditional economic models.
    - **Insensitivity to sample size** explains how people underestimate the influence of sample size on probability judgments. For instance, individuals may assign similar probabilities to rare events in small and large samples. This bias can lead to incorrect conclusions when assessing probabilities based on limited data.
    - **Less-is-better effect** is a type of preference reversal that occurs when the lesser or smaller alternative of a proposition is preferred when evaluated separately but not evaluated together. The term was first proposed by Christopher Hsee.
    - **Probability neglect**, coined by Cass Sunstein, is when people often ignore or exaggerate the importance of probabilities when making decisions under uncertainty. Small risks are usually ignored or blown out of proportion, with little consideration for the middle ground. This bias is distinct from other related biases involving probability, as it involves disregarding probability altogether when making decisions.
    - **Scope neglect** is when the valuation of a problem doesn't scale proportionally with its size. For example, people may be willing to pay almost the same amount to prevent harm to 2,000 or 200,000 birds, showing little sensitivity to the scope of the issue. This bias is related to how people form judgments based on mental prototypes and is linked to the phenomenon of mass numbing, where harm to a large group is given less importance than harm to an individual.
    - **Zero-risk bias** is when people favour completely eliminating a small risk over options that reduce overall risk more. It's commonly seen in decisions about health, safety, and the environment. Surveys using hypothetical scenarios have shown their impact on decision-making.
- **False priors** refer to erroneous or biased prior beliefs that individuals hold about events, people, or situations. These incorrect beliefs can lead to cognitive biases such as confirmation bias, stereotyping, attribution errors, illusory correlations, and false memories. False priors influence perception, judgment, and decision-making processes and are studied by psychologists to understand their impact on human behaviour.
    - **Agent detection** is the inclination for animals, including humans, to presume the purposeful intervention of a sentient or intelligent agent in situations that may or may not involve one.
    - **Automation bias** is when people trust automated systems more than human-made decisions, even when the automated suggestions are wrong. This can be a problem in critical areas like aviation and healthcare, leading to errors because people rely too much on machines.
    - **Sexism** or **gender bias** is when people discriminate against or treat others unfairly because of their gender. It mostly affects women and girls and can be linked to stereotypes and thinking one gender is better than the other. In severe cases, sexism can lead to things like sexual harassment and violence. It can happen in places like workplaces due to cultural norms.
    - **Sexual overperception bias** is when an individual tends to perceive sexual interest or attraction from others more often or intensely than is actually the case. This bias can lead someone to misinterpret friendly or neutral behaviour as romantic or sexual interest. It can result in misunderstandings and discomfort in social interactions.
    - **Stereotype** is a general belief about a group of people, which can be about their personality, appearance, or abilities. Stereotypes are often not entirely true and can be resistant to change. They can be positive, neutral, or negative perceptions about a group.
- **Framing effect** is when people's decisions are influenced by whether options are presented in a positive or negative way. When it's positive, people tend to play it safe, and when it's negative, they try to avoid losses. This happens even if the options are essentially the same but described differently. For instance, it affects choices related to saving lives, treating patients, or financial gains or losses.
    - **Contrast effect** is when our perception, thinking, or performance is influenced by a previous or simultaneous stimulus of lesser or greater value in the same dimension. For example, a grey object can seem lighter or darker when placed next to a lighter or darker object, respectively. This phenomenon affects how we perceive, think, and perform relative to what we've experienced before.
    - **Decoy effect** happens when adding a less appealing third option influences people's preference between two other options. In marketing, this third option is intentionally made worse than one of the other choices and better than the other in certain aspects. This decoy makes people more likely to choose the better option of the original two. It's a violation of a decision theory principle where a new option shouldn't make existing ones more popular.
    - **Default effect** is when people tend to go with the standard option if they don't make a specific choice. For example, if a company sets a default temperature for air-conditioning, most people won't change it. This idea is used to influence people's decisions, like getting them to agree to email marketing or renew subscriptions automatically.
    - **Denomination effect** is when people are less likely to spend big bills compared to the same amount on small bills. Research suggests that people tend to spend more when they have smaller bills. This effect can impact spending decisions and has implications for things like consumer behaviour and monetary policy. For example, during tough economic times, people may use coins instead of larger bills to feel more thrifty.
    - **Distinction bias** occurs when people perceive two options as more different when viewed together than when considered separately. For instance, if offered an apple, you might happily eat it. But if presented with two apples - one slightly fresher - you might choose the fresher one and later claim you wouldn't have enjoyed the other, even though you were initially content with it. This bias arises from our tendency to exaggerate differences when comparing things.
    - **Domain neglect bias** is when individuals fail to consider the specific domain or context when evaluating a statement or claim. Instead, they rely on general knowledge or stereotypes, which may not be applicable to the particular situation. This bias can lead to incorrect judgments or decisions because it overlooks crucial domain-specific information.
- **Logical fallacy** is a flaw in reasoning that makes an argument invalid or unsound. These errors often appear persuasive but contain deceptive or faulty logic, irrelevant information, or false assumptions. Recognizing and avoiding fallacies is essential for constructing solid, valid arguments and promoting critical thinking.
    - **Berkson's paradox**, also known as **Berkson's bias**, is a tricky situation in statistics. It occurs when there's a bias in how data is collected in a study. This can make it seem like there's a connection between two things when there actually isn't. It's important to be aware of this in fields like medical statistics.
    - **Escalation of commitment** is when people keep going with a decision or action even if it's not working out well. They stick with it because they've already invested time or effort, even if it doesn't make sense. This is similar to the idea of throwing good money after bad.
    - GI Joe fallacy is thinking that just knowing about a bias is enough to beat it. It's like thinking you've won half the battle by being aware, but in reality, you need more than awareness to overcome biases.
    - **Gambler's fallacy** is a mistake in thinking that if something happened a lot before, it won't happen as much in the future, or the other way around. This is wrong because some events are independent of what happened before. It's often seen in gambling, like thinking a dice roll is more likely to be a six just because there were fewer sixes before.
    - **Hot hand** is a belief that if you succeed once, you're more likely to succeed again. It's often talked about in sports, like basketball. Some studies support this idea, but not all. Only a few players might actually have a hot hand, and even if they do, it doesn't make a huge difference.
    - **Plan continuation bias** is when individuals persist with a previously chosen plan of action despite changing circumstances or evidence suggesting that the plan is no longer the best option. This bias can lead to poor decision-making and a failure to adapt to new information or conditions.
    - **Subadditivity effect** is the tendency to judge the probability of the whole to be less than the probabilities of the parts.
    - **Time-saving bias** is the tendency to underestimate the time that could be saved or lost when increasing or decreasing from a relatively low speed, and to overestimate the time that could be saved or lost when increasing or decreasing from a relatively high speed.
    - **Zero-sum bias** is when people tend to think that a situation is always win-lose, where one person's gain is another's loss, even when it's not true. This bias leads to incorrect beliefs and decisions, often called the fixed-pie fallacy in economics.
- **Prospect theory**, by Kahneman and Tversky in 1979, explains how people view gains and losses differently. It shows that losing \$1,000 hurts more than gaining \$1,000 feels good. This challenges the idea that people always make rational decisions and is based on experiments. Kahneman received a Nobel Prize for it in 2002.
    - **Ambiguity effect** is a bias in decision-making caused by not knowing all the facts. It means people often choose options with known probabilities of success rather than ones with unknown probabilities. Daniel Ellsberg talked about this in 1961.
    - **Disposition effect** in finance is when investors sell profitable assets and hold onto losing ones because they fear losses more than they value gains. Discovered by Shefrin and Statman in 1985, it's tied to prospect theory, which explains how people make decisions to avoid losses. Hedonic framing can help lessen this effect.
    - **Dread aversion**, also known as **loss aversion**, is when people tend to strongly avoid situations or decisions that provoke feelings of dread or fear. It's part of the broader concept of loss aversion, where individuals tend to prioritise avoiding losses over acquiring equivalent gains. Dread aversion reflects the idea that people will go to great lengths to prevent or mitigate situations they find highly distressing or frightening.
    - **Endowment effect** is when people place higher value on objects they own compared to those they don't. It means they're more likely to keep something they have than to acquire the same thing when they don't own it. For instance, people might be unwilling to trade a pen for a coffee mug, even if they initially got both items. This effect also occurs when people feel more attached to things they own, even if it's just for a short time.
    - **Pseudocertainty effect** happens when people see an outcome as certain even though it's actually uncertain in a multi-stage decision. They tend to ignore how certain an outcome was in a previous stage when making decisions in later stages. This is different from the certainty effect, and it was discovered while trying to make decision theory more accurate for the certainty effect.
    -  **Status quo bias** is when people prefer things to stay the same and resist making changes. They see the current situation as positive and any change as a loss. This bias affects decision-making and intersects with other cognitive processes like loss aversion. It's seen in various areas like economics, health, and ethical choices.
    - **System justification theory** posits that people have needs like stability and positive self-image, which lead them to defend and justify the existing system, even if it's unfair. This can result in out-group favouritism, where lower-status groups accept their inferiority and view higher-status groups positively. People simultaneously support and are victims of the system's norms, making change difficult.
- **Self-assessment** means looking at yourself to understand who you are. It's one of the reasons we evaluate ourselves, along with confirming our self-concept and boosting our self-knowledge. Unlike the other self-evaluation motives, self-assessment focuses on the accuracy of how we see ourselves right now, not on making ourselves look better. This can sometimes lower our self-esteem.
    - **Dunning-Kruger effect** is when those with limited skills tend to overestimate themselves, while highly skilled individuals may underestimate their abilities. It's often misunderstood as a sign of low intelligence, applying to various tasks and measured by comparing self-assessment to performance. It can lead to poor decisions and hinder self-improvement.
    - **Hot-cold empathy gap** happens when people underestimate how their current emotions influence their thoughts and actions. For instance, when angry, they might struggle to comprehend calmness. This can complicate medical diagnoses. It can flow from hot to cold emotions or the reverse and relate to past, present, or future situations, either within oneself or when understanding others.
    - **Hard-easy effect** is when people tend to think they'll do better at difficult tasks than they actually will and underestimate their performance on easy tasks. This happens because they compare themselves to others when evaluating their abilities. It's like thinking you'll ace a hard test but do worse on an easy one.
    - **Illusion of explanatory depth** is when people believe they understand something complex better than they actually do. For instance, they might think they can fix a bicycle but struggle when actually doing it. This bias applies to various fields, including politics, and resembles the Dunning-Kruger effect, but pertains to knowledge rather than skills. It affects most individuals, including experts, and is more pronounced when the topic is considered socially significant.
    - **Impostor syndrome** is when people doubt their abilities and fear being exposed as frauds despite evidence of their competence. They may think they're deceiving others or not as smart as they seem. It can affect anyone, not just high-achieving women, and may lead to mental health issues. Treatment options exist, but it's not a formal mental disorder.
- **Truth judgment** involves assessing the truth or falsity of statements using evidence and logical reasoning. It's crucial in critical thinking, distinguishing between truth and falsehoods, and vital in fields like philosophy, science, journalism, and law, where accuracy matters.
    - **Belief bias** means we often judge arguments based on whether their conclusions align with our beliefs rather than their actual strength. We tend to accept arguments that match our values and reject those that don't. This bias can lead to errors in reasoning across various tasks.
    - **Illusory truth effect** is when we tend to believe something is true just because we've heard it repeatedly, even if it's false. This happens because our brains find familiar things easier to accept. It's linked to hindsight bias, where we remember being more confident in something once we know it's true. This effect is used in advertising, news, and politics to make false information seem true through repetition.
    - **Rhyme-as-reason effect** is when people think a saying is truer if it rhymes. In experiments, people rated rhyming sayings as more accurate than non-rhyming ones, even when the meaning was the same. This might happen because we like things that sound good (Keats heuristic) or are easy to understand (fluency heuristic).
    - **Subjective validation** is when people believe something is true because it's personally meaningful to them, even if there's no real connection. It's like interpreting vague horoscopes as accurate because they align with one's self-image, leading to biased beliefs and actions.

## Memory

- **Misattribution of memory** happens when you mix up where a memory comes from. It often occurs when you can't control your feelings while remembering things. There are three types: cryptomnesia (forgetting the source), false memories (remembering things that didn't happen), and source confusion (mixing up where a memory came from). This was part of Daniel Schacter's study on memory errors.
    - **Cryptomnesia** is when a forgotten memory comes back, but you don't realise it's from the past. You might think it's a new idea, but it's actually something you remembered but forgot where it came from. It's like unintentional plagiarism of your own memory.
    - **False memory** is when you remember something that never really occurred or remember it in a different way from what actually happened. This can happen because of suggestion, mixing up information, or confusing the source of the memory.
    - **Source confusion** occurs when people confuse the origins of their memories. For instance, they might hear something from others and later believe they witnessed it themselves, leading to memory errors. Sometimes, real experiences get mixed up with imagined or heard events, causing significant consequences, such as wrongful accusations, as seen in a case involving Ronald Reagan.
    - **Social cryptomnesia** is when people and society forget where a change came from. They remember the change but not how it happened or who made it happen. This can make it seem like those who worked for the change get less recognition, especially minorities who made sacrifices for it.
    - **Suggestibility** is when someone easily accepts and acts on suggestions from others, even if those suggestions are false. It can make people remember things differently because they've been told something repeatedly. People with strong emotions are more susceptible to this. Suggestibility generally decreases with age, but individual self-esteem and assertiveness levels can make some more suggestible than others.
    - **Perky effect** occurs when actual images can impact imagined ones, or when real images are mistakenly recalled as imagined instead of real.

## Social

- **Association fallacy** is a mistake in logic where it's assumed that if two things belong to the same group, they must share the same properties. For instance, thinking all animals are dangerous because some are. When it's used to make people dislike something by linking it to something they already dislike, it's called guilt by association. It's like saying your dog is dangerous just because it's an animal, exploiting people's existing dislike of animals.
    - **Authority bias** is when people give more weight to the opinion of an authority figure, regardless of what they're saying. People tend to obey and believe authority figures because they're seen as credible. This bias is linked to our natural inclination to respect authority, and it can vary between cultures. For example, in Eastern Europe, this bias is stronger than in Western Europe.
    - **Cheerleader effect** is when people appear more attractive in a group than when alone, about 1.5-2.0% more. This idea comes from the belief that being in a group makes you look better, possibly because it shows you're social. It can affect things like dating, marketing, and social media strategies.
    - **Halo effect** is when your positive impression of one thing or person makes you think positively about other aspects of it, even if it's not true. For example, if someone looks good in a photo, you might assume they're a good person, which isn't always accurate. It's a bias based on your own preferences and beliefs.
- **Attribution bias** is when people make errors in judging why they or others behave in certain ways. It happens because we tend to see things in a biased way, not always accurately. For example, if someone cuts you off in traffic, you might blame their personality instead of considering other factors. There are various types of attribution biases, each showing different tendencies in how people explain behaviour. Researchers have studied these biases to understand how they affect emotions and actions.
    - **Actor-observer bias** is when people explain their own actions by pointing to the situation, but when explaining someone else's actions, they often blame the person's personality. This bias is sometimes called the fundamental attribution error. Originally, it was believed that this bias was strong, but recent research found it's not as clear-cut. It's important in various fields like philosophy, management, and political science.
    - **Fundamental attribution error** is when we wrongly think someone's behaviour is because of their personality, ignoring the situation. For example, assuming someone's late because they're selfish, when it might be because of traffic. It's a mistake because it overlooks the role of circumstances in behaviour.
    - **Extrinsic incentives bias** is when we think others are motivated by external rewards like money, but we see ourselves as motivated by internal reasons like learning. This is different from the fundamental attribution error, where we often judge others as having internal motivations. This bias can explain why adding external rewards to something we enjoy can sometimes make it less enjoyable.
    - **Defensive attribution** is when someone blames others for a mishap to feel safer and protect their self-esteem. They're less likely to blame similar people and more likely to believe the mishap was preventable. This is a cognitive bias because it's based on emotions and desires, not just facts.
    - **Group attribution error** is when we assume that the behaviour of one person in a group represents everyone in the group or that a group's decision reflects what each individual in the group wants, even if evidence shows otherwise. It's similar to the fundamental attribution error but applies to groups.
    - **Hostile attribution bias** is when someone often thinks that others have bad intentions, even when there's no clear evidence of it. For example, if people are laughing nearby, they might assume it's about them. This bias can lead to aggressive behaviour, especially in kids who show it consistently. It can also be caused by experiences like teasing or harsh parenting. Understanding and addressing this bias can help prevent aggression.
    - **Intentionality bias** is the inclination to perceive human actions as deliberate rather than unintentional.
    - **Just-world hypothesis** is the belief that people generally get what they deserve, with good deeds being rewarded and bad ones punished. This can lead to the idea of cosmic justice or karma. It's often used to rationalise suffering, assuming that those who suffer must somehow deserve it. This belief appears in phrases like what goes around comes around and has been studied by psychologists for decades.
    - **Moral luck** refers to situations where a person is judged morally for actions or outcomes, even when they didn't have complete control over them. Bernard Williams introduced this concept, and it has been explored further in essays by Williams and Thomas Nagel, shedding light on its importance in shaping a comprehensive moral theory.
    - **Self-serving bias** is the tendency to attribute personal success to one's abilities while blaming external factors for failures. For example, someone may credit intelligence for a good grade but fault a teacher for a bad one. It safeguards self-esteem but distorts thinking, occurring in work, relationships, sports, and decisions. Motivation and cognition influence it, and research employs self-reports and physiological measures.
    - **Ultimate attribution error** is when we judge people from different groups more harshly for negative actions, attributing them to their personality, while we give our own group the benefit of the doubt, blaming external factors. This can fuel stereotypes and bias. It also leads us to credit our own group more for positive actions. This concept highlights how group membership can unfairly shape our judgments.
    - **Implicit bias** refers to the unconscious attitudes, stereotypes, and beliefs that people hold about certain groups of people. These biases can affect our decisions and actions, even when we are not aware of them. They often result from socialisation and cultural influences. Implicit bias can lead to unintentional discrimination and inequality in various areas of life, including hiring, education, and criminal justice. Recognising and addressing implicit bias is essential for promoting fairness and reducing discrimination.
- **Conformity** is when people adjust their attitudes, beliefs, and actions to fit in with a group or follow common norms. This happens because it's often easier to go along with what others do than go your own way. Conformity can be conscious or unconscious, and it can result from peer pressure, a desire for security, or the belief that the group knows better. It can be good when it helps societies function smoothly, but it can also lead to negative outcomes. Factors like culture, gender, and group size influence how much people conform.
    - **Availability cascade** is when a simple and popular idea spreads rapidly in society because it seems insightful. People adopt it to fit in and appear up-to-date. This happens because the idea is easy to understand and makes them seem sophisticated. It was first described as part of information cascades in finance and risk assessment.
    - **Availability heuristic** is a mental shortcut where people judge things based on what easily comes to mind. If something is easily remembered, it's seen as more important. This tends to favour recently acquired information. The easier it is to recall the consequences of something, the more important they seem.
    - **Bandwagon effect** is when people do something or believe in something because they see others doing it. It's like following a crowd without thinking too much. This happens because people want to fit in or be part of a group. It can lead to trends, but it can also be fragile and change easily. Sometimes, people do the opposite of what others are doing because they want to be different.
    - **Response bias** refers to the tendency for people to answer questions inaccurately or falsely in surveys or interviews. Many factors can cause this, like how questions are asked, the researcher's attitude, or the participant's desire to give socially acceptable answers. Response bias can affect the validity of research findings, and researchers need to be aware of it to prevent its negative impact.
    - **Groupthink** is when people in a group prioritise harmony and agreement over making rational decisions. They may avoid conflicts and quickly agree, leading to poor choices. This phenomenon is studied in psychology and has implications in communication, politics, management, and even deviant religious cult behaviour.
    - **Groupshift** is when people in a group tend to take more extreme positions than they would alone. For example, if a group is generally cautious, they may become even more cautious in their decisions. On the other hand, if the group is generally willing to take risks, they may become even more risk-seeking when deciding together. This happens because, in a group, people feel less individual responsibility for risks.
    - **Social-desirability bias** is when people in surveys or research tend to answer questions in a manner that will be viewed favourably by others. They might exaggerate their good behaviour or hide their bad behaviour. This can be a problem in research because it makes it hard to get accurate information from people.
    - **Truth bias** is the tendency to assume that others are telling the truth in social interactions. It leads to trust and acceptance of information without critical evaluation, but can also make individuals vulnerable to deception when others lie. This bias affects judgments and decisions in interpersonal contexts.
    - **In-group favouritism** is when people favour those in their group over outsiders. This can influence how they judge others or allocate resources. It's studied in psychology, often related to group conflicts and prejudice. Cultural groups formed around traits can lead to this bias. The two main theories explaining it are realistic conflict theory, which relates it to competition for resources, and social identity theory, which connects it to a desire for a unique group identity.
    - **Not Invented Here** is when people or groups avoid using outside products or knowledge. It's common in social, corporate, or institutional settings. This can occur for reasons like wanting to support local businesses, legal concerns, or not appreciating foreign ideas. It's a social behaviour where people reject foreign ideas or products, potentially missing out on valuable opportunities. The opposite approach is sometimes called **Proudly Found Elsewhere** or **Invented Elsewhere**.
    - **Out-group homogeneity effect** is when people think those in another group are more alike, while those in their own group are seen as more diverse. This can lead to stereotypes about the other group, assuming they all share the same traits. It happens when people have limited exposure to the other group and don't have personal experiences with their diversity. Researchers study this in situations involving conflicts, prejudice, and stereotypes to learn how it affects social interactions.
    - **Cultural bias** is when people judge things based on their own culture's standards. It can be a problem in social and human sciences. Some experts in these fields try to find ways to avoid cultural bias. It happens when people assume that their culture's way of doing things is the only right way. This can affect things like language, justice, and how they see evidence and taboos.

# Contextual Biases

Contextual biases are biases influenced by the situation. They lead to judgments not solely based on facts but shaped by circumstances, surroundings, or social factors. These biases affect decisions, perceptions, and behaviour, often unconsciously. Recognising and addressing them is crucial for fairness and objectivity in areas like hiring, education, and social interactions.

## Academic

- **Academic bias** is when scholars let their beliefs influence their research and the scientific community. Some people claim there's bias against political conservatives and Christians in academia, but others say this is based on anecdotal evidence and that it might be because conservatives are less likely to pursue academic careers. Classroom bias may also be linked to issues like sexuality, race, class, and gender, not just religion.
    - **Funding bias** means that a scientific study may support the interests of its financial sponsor. Researchers even investigate past studies to check for this bias. It can happen because researchers feel obliged to their employers, misconduct, publication bias, or reporting bias.
    - **Publication bias** is when studies with positive results are more likely to be published than those with negative results. This can make it seem like something works better than it does. It's a problem because it can lead to wrong conclusions and waste resources. It's often seen in medical research, where negative results can be as important as positive ones.
    - **FUTON** (full text on net) bias is when scholars prefer to cite journals with free online access over those you have to pay for. This happens because it's easier to find and read articles with free access. It can boost the impact of free-access journals.
    - **NAA** (no abstract available) bias is similar, where scholars prefer articles with online abstracts over those without.
    - **Educational bias** involves real or perceived unfairness in the education system. It often relates to the content of school textbooks, where selective removal of critical information is called whitewashing. Religious bias can occur in countries where religion has a strong influence on education. This bias can take various forms, including teacher bias and prejudice against women in STEM (science, technology, engineering, and mathematics) fields.
    - **Inductive bias** refers to the set of assumptions a learning algorithm makes to predict outputs for new inputs based on the training data. It guides the algorithm in making generalizations and influences how it interprets and learns from data, shaping its predictions and decisions.
    - **Algorithmic bias** occurs when computer algorithms produce results that are systematically prejudiced due to flawed assumptions, design, or data. This can lead to unfair outcomes, such as discrimination in hiring, lending, or law enforcement, often reflecting existing societal biases.

## Law Enforcement

- **Law enforcement bias** refers to the prejudices and discriminatory practices within law enforcement agencies that lead to unequal treatment of individuals or groups. This bias can manifest in various forms, such as racial profiling, unequal enforcement of laws, and disparities in policing practices, often disproportionately affecting marginalised communities.
    - **Driving while black** refers to racial profiling of African-American drivers, suggesting they may be stopped by police due to racial bias rather than a valid traffic violation. It plays on the phrase driving while intoxicated.
    - **Racial profiling** is when someone is suspected or targeted because of their race, rather than individual suspicion or evidence. It's often associated with law enforcement and can lead to discrimination against minority groups.
    - **Victim blaming** happens when the person who suffered harm is partly or fully blamed for what happened to them. This can be seen in cases of domestic violence and sexual crimes, where victims are sometimes unfairly blamed, especially when they know the perpetrator beforehand.
    - **Insider trading** is when people with secret information about a company trade its stocks or securities. This is illegal in many places because it's unfair to regular investors who don't have this special information. Insiders could make much bigger profits, and that's seen as unfair.
    - **Match-fixing** is when someone manipulates the outcome of a sports match, game, or event to ensure a specific result, usually for financial gain. This unethical practice can involve players, officials, or others involved in the sport, and it undermines the fairness and integrity of the competition. Match-fixing is widely condemned and illegal in most sports and countries, with severe penalties for those involved.
    - **Spot-fixing** is a form of corruption in sports, particularly in cricket and some other sports, where individuals manipulate specific aspects of a game rather than the overall result. It typically involves betting on or arranging events within the game, such as the timing of no-balls or wides in cricket, without necessarily altering the final outcome of the match.

## Media

- **Media bias** refers to the tendency of news organisations to favour particular perspectives, ideologies, or political views in their reporting. This bias can impact the way news stories are framed, the selection of sources, and the overall tone of coverage. It can be intentional or unintentional and may affect public perception of issues and events. It's crucial for consumers of news to be aware of potential bias and seek diverse sources for a well-rounded understanding of current events.
    - **Media manipulation** involves using various techniques to create a biased image or argument that serves a specific agenda. These tactics can include logical fallacies, deception, propaganda, and the suppression of opposing views. It's used in fields like public relations and marketing. While the goals may differ, the methods often involve distracting the public to control their perception.
    - **Agenda setting** is when the media repeatedly covers a story, making the audience see it as important and increasing its significance.
    - **Gatekeeping** is the process of selecting and shaping information before it reaches the public. It decides what information gets shared and how it's presented in the media.
    - **Sensationalism** is when news stories are exaggerated or presented in an overly dramatic way to grab attention, often distorting the truth or focusing on unimportant details. It can make significant events seem less important or present trivial topics as major news, going against the principles of responsible journalism.

# Statistical Biases

Statistical bias means that data collection is skewed and can lead to misleading results. It happens due to how samples are chosen or data is collected, causing the results to differ from the true value being estimated.

## Systematic

- **Systematic bias** is the inherent tendency of a process to support particular outcomes. This can happen because of errors in sampling, measurement, or analysis. It's a problem in research because it can make findings unreliable. Systematic bias can be avoided by using random sampling, standardised measurements, and careful analysis.
    - **Experimenter bias** is when researchers' expectations or beliefs influence the results of an experiment. This can happen because they might unconsciously influence participants or interpret results in a biased way. To avoid this bias, researchers can use double-blind studies, where neither the participants nor the researchers know who's in each group.
    - **Observer bias** is a type of detection bias where observers tend to see what they expect or want to see rather than accurate facts. This can be a problem in scientific research as it can lead to over- or underestimation of true findings, compromising the validity of the study. This bias is more likely when researchers have vested interests or strong preconceptions. Examples of other cognitive biases include anchoring, the bandwagon effect, confirmation bias, and more.
    - **Reporting bias** happens when people selectively share or hide information. In health studies, it can involve not revealing past medical history or habits like smoking. In research, it means not reporting unexpected, unwanted results, and blaming errors instead. This can create a cycle where others do the same, leading to a cascade of reporting bias.

## Selection

- **Selection bias** happens when samples for analysis aren't randomly chosen, making them unrepresentative of the intended population. This can distort statistical analysis and lead to incorrect study conclusions if not considered.
    - **Sampling bias** is when a sample isn't representative of the population it's supposed to represent. This can happen if the sample is too small, not random, or not diverse enough. For example, if you want to know how people in a country feel about a new law, but you only ask people in one city, your results won't be accurate. This bias can lead to wrong conclusions and is a common problem in research.
    - **Time interval bias** is when the time between two events is too short or too long, leading to incorrect conclusions. For example, if you want to know how often people go to the doctor, but you only ask about the last week, you might miss those who go less often. This can lead to wrong conclusions because the time interval isn't right.
    - **Undercoverage bias** is when some groups in a population are less likely to be included in a sample. This can happen if the sample is chosen in a way that doesn't give everyone an equal chance of being included. For example, if you only survey people who have internet access, you might miss those who don't. This can lead to incorrect conclusions because the sample isn't representative of the whole population.
    - **Overcoverage bias** is when some groups in a population are more likely to be included in a sample. This can happen if the sample is chosen in a way that gives some people a higher chance of being included. For example, if you survey people who live in cities more than those in rural areas, you might get more urban opinions. This can lead to incorrect conclusions because the sample isn't representative of the whole population.
    - **Survivorship bias** occurs when we only look at successes and ignore failures, leading to wrong conclusions. For example, in finance, we might think all investments are profitable because we only see the successful ones. It can also make us believe successful things are special when luck is involved. In accidents, it can make us underestimate danger because we only hear from survivors. To avoid this bias, consider both successes and failures for a complete understanding.

## Participation

- **Participation bias** or **non-response bias** happens when the people who don't answer a survey are different from those who do in a way that matters for the study. Imagine asking kids in a class if they like homework. If only the kids who like homework answer, then the results won't show how the whole class really feels. This can make the survey results misleading.
    - **Volunteer bias** is when people who volunteer for a study are different from those who don't. This can happen because volunteers are often more interested in the topic or have more time. This can lead to incorrect conclusions because the sample isn't representative of the whole population.
    - **Response bias** is when people don't answer survey questions honestly. This can happen because they want to look good, don't understand the question, or don't remember the answer. It can lead to incorrect conclusions and is a common problem in research.
    - **Recall bias** is when people don't remember things accurately. This can happen because they forget, remember things differently, or want to look good. This can lead to incorrect conclusions and is a common problem in research.
    - **Hawthorne effect** is when people change their behaviour because they know they're being watched. This can lead to incorrect conclusions because they don't act the same way when they're not being watched.

# Conflicts of Interest

A conflict of interest occurs when someone or a group has interests that overlap, like financial or personal ones, which could lead to corruption. This conflict can exist even before any wrongdoing occurs and should be addressed to prevent bias in decisions. It's when there's a risk that personal interests might unduly influence professional judgments or actions related to their main responsibilities.

- **Bribery** is giving something valuable, like money or gifts, to influence someone's actions. It can involve various things like money, property, favours, and more. What's seen as bribery can vary by location. In some places, even political campaign contributions can be considered bribery, while in others, they're legal if they follow election rules. Similarly, tipping is seen as bribery in some societies but not in others.
- **Lobbying** is trying to influence decisions made by government officials, like lawmakers. Lobbyists can represent various groups, and they might do it as a job or not. Some see lobbying as corrupt because it's often associated with powerful people shaping laws for their benefit. When officials have a duty to serve the public but also benefit from private interests, there's a conflict of interest, and lobbying can influence debates on various topics.
- **Favouritism** means showing preference to people in your group over those outside it. It can affect how you judge others or share resources. Psychologists study it and connect it to group conflicts and prejudice. Cronyism is when you favour your long-time friends, even if they're not qualified, for important positions. Nepotism is favouritism towards your relatives.
- **Nepotism** is when someone in power gives jobs or favours to their relatives, even if they're not the best choice. This can happen in politics, business, or other areas. It's seen as unfair because it can lead to unqualified people getting important jobs. It can also create conflicts of interest and harm the organisation.
- **Shill** is someone who secretly promotes a person or group without revealing their connection. They can be found in media, marketing or politics. Shills often pretend to be enthusiastic supporters to influence others. They may work with salespeople or marketing campaigns. Shilling is against the law in many cases because it can lead to fraud. But sometimes, when it doesn't harm anyone, it's allowed, like when someone in the audience laughs or participates in a show as part of the act.
- **Self-regulation** means that an organisation checks if it follows rules on its own, instead of an outside group checking for them. But this can create a conflict of interest. If a group, like a company or government, is asked to stop bad behaviour within their own group, they might focus on looking good instead of fixing the problem.
- **Regulatory capture** is a type of corruption. It happens when a government agency, meant to protect the public, starts favouring big businesses or special interest groups. This happens because these groups put a lot of effort into getting the rules they want, while regular people often don't pay much attention. It's a risk for any regulatory agency.

# Prejudices

Bias and prejudice are closely linked. Prejudice is forming opinions about someone before knowing the facts, often based on characteristics like gender, age, or race. It can also involve holding irrational beliefs or unreasonable attitudes that are hard to change.

## Forms

- **Structural discrimination** at the macro level involves societal systems and structures that perpetuate inequality across various institutions and sectors, often without explicit intent. It arises from interconnected institutions and historical legacies that create and maintain disparities in areas like education, employment, housing, and healthcare.
- **Institutional discrimination** at the meso level refers to policies, practices, and procedures within organisations and institutions that systematically disadvantage certain groups. It occurs when discriminatory practices are embedded in the norms, rules, and laws of an institution.
- **Taste-based discrimination** at the micro level is when people are treated unfairly based on personal preferences or biases. It can involve negative attitudes towards certain groups, leading to unequal treatment. This form of discrimination is based on individual preferences rather than objective criteria. It can affect various areas like hiring, housing, and social interactions.

## Attributes

### Macro level

- **Nationalism** is the belief that a nation should govern itself independently and have its own state. It aims to create a shared identity based on culture, language, and history. Nationalism comes in different types, mainly ethnic and civic. It developed in response to modernisation and is viewed as an imagined community. Its moral value and impact differ based on ideology, ranging from positive pride to negative divisions and minority suppression.
- **Fascism** is an authoritarian ideology marked by dictatorial power, extreme nationalism, suppression of dissent, and centralised government control. It often includes elements of racism, militarism, and totalitarianism. Fascist regimes, like Nazi Germany and Fascist Italy, sought total control, ultranationalism, and restricted freedoms, causing human rights abuses and violence.
- **Nazism**, short for **National Socialism**, is an extreme far-right ideology linked to Adolf Hitler's Nazi Germany during the 1930s and 1940s. It espouses extreme nationalism, authoritarianism, racism, anti-Semitism, and the pursuit of a racially pure and totalitarian state. Nazism led to the Holocaust and was marked by expansionism and militarism. After World War II, it was discredited, and Nazi leaders were tried for war crimes at the Nuremberg Trials.
- **Racism** is when people are treated unfairly because of their race or ethnicity. It can be shown through negative attitudes or actions towards those of different racial backgrounds, leading to unequal treatment and social inequality. Racism can take different forms, from individual biases to unfair systems in society. It's widely seen as unjust and harmful, causing division and inequality.
- **Scientific racism** is the false belief that different human races exist and can be ranked as superior or inferior based on biology. This idea was once accepted in science but is now discredited. It involved categorising people into separate races and assigning physical and mental traits to these groups. While it was common in the past, it's now widely rejected as unscientific and harmful. The term is often used critically when referring to modern theories that link race and intelligence without solid evidence.
- **Speciesism** is when individuals are treated differently based on their species, like discrimination but for animals. It often leads to humans thinking they can use animals however they want, like in farming or experimentation. Some who support this also tend to have prejudiced views towards humans of different races and genders. It's a controversial topic with philosophers and animal rights activists debating its ethics and morality.

### Meso level

- **Classism** is discrimination based on social class. It involves bias, unfair behaviour, and policies that favour the wealthy over the less privileged. Social class is how people are ranked based on their money, education, jobs, and connections.
- **Colorism** stems from differences in skin tones, even within the same racial or ethnic group. It can involve favouring individuals with lighter skin tones over those with darker skin tones and is rooted in historical, social, and cultural factors. Colorism can lead to unfair treatment, bias, and unequal opportunities in areas such as education, employment, and social interactions. It is particularly prevalent in societies with a history of colonialism, slavery, or colour-based caste systems.
- **Rankism** is when people misuse their power to unfairly control or demean others because of their social or hierarchical status. It can happen at work, socially, or in institutions and often causes unequal treatment and emotional harm. Rankism opposes such behaviour and advocates for equal respect, regardless of someone's social status.
- **Multiculturalism** is a social and political ideology that promotes the coexistence of diverse cultural groups within a single society. It encourages respect for different cultural backgrounds, traditions, and values. Multiculturalism aims to create inclusive and harmonious societies where people of various ethnicities, religions, and backgrounds can live together, contributing to the richness of the overall culture.

### Micro level

- **Ableism** is unfair treatment or bias against people with disabilities. It includes negative attitudes and stereotypes, leading to unequal opportunities and exclusion. This discrimination can happen in areas like education, work, healthcare, and social situations. The goal is to combat this discrimination and make sure people with disabilities have equal rights and are included in society.
- **Sanism** is when people face discrimination or oppression because others think they have a mental disorder or cognitive issues. This happens because of stereotypes about neurodiversity. Sanism can show up in many ways, like unfair treatment, insults, or even clear discrimination. It affects those with conditions like autism, ADHD, and more. It's not just about how the public treats them. It also happens in mental health care, the legal system, and other places.
- **Lookism** is when people are unfairly treated because they're considered unattractive. This happens in dating, social situations, and workplaces. Lookism doesn't get as much attention as racism or sexism, and it often lacks legal protection. But it still affects people's chances of dating, jobs, and more. Good-looking people tend to be seen more positively, with benefits in friendships, social skills, and even their love lives.
- **Sizeism** is discrimination based on body size or weight. It involves unfair treatment, stereotypes, and biases against people perceived as overweight or underweight. Sizeism affects areas like employment, healthcare, media representation, and social interactions, leading to body shaming and unequal opportunities. This form of discrimination can harm physical and mental health.
- **Ageism** is when people discriminate against others or treat them unfairly because of their age. It was first coined in 1969 to describe discrimination against older people, but it can also affect younger individuals. Ageism can involve unfair treatment, stereotypes, or policies that favour one age group over another. It's not based on biology but on social perceptions.
- **Sexism** is when people discriminate based on gender. While it can affect anyone, it mainly targets women and girls. It's tied to stereotypes and the belief that one gender is better than the other. Extreme sexism can lead to sexual harassment and violence. It often leads to inequality, like in the workplace, and stems from societal norms.
- **Sexual orientation discrimination** targets individuals based on their sexual orientation, like being gay or lesbian. It often involves negative attitudes like homophobia. Heterosexism is when heterosexual individuals show bias against lesbian, gay, and bisexual people, asserting that heterosexuality is the only normal orientation, similar to sexism or racism. It deals with cultural biases against non-heterosexuals, while homophobia focuses on individual bias and its impact on heterosexual individuals.
- **Religious discrimination** is when someone is treated unfairly because of their religious beliefs. This can happen in various settings like work or housing. It's related to religious persecution, which can include extreme cases like executions for heretical beliefs. Even in places with religious freedom, minority religions may face discrimination. These issues can involve legal policies interfering with religious matters.
- **Linguistic discrimination** refers to unfair treatment or prejudice towards individuals based on their language, including aspects like accent, vocabulary, or syntax. This discrimination can lead to biased judgments about a person's education, social status, or character due to their use of language. It often occurs in various contexts and can be influenced by cultural and historical factors, favouring dominant languages while disadvantaging less dominant ones.
- **Dialect discrimination** is when people are treated unfairly because of the way they speak, particularly if their speech shows they're from a specific place or social group. This can happen in various situations, but it's often seen in the workplace where employers may prefer a more standard way of speaking. It can also affect education and politics, where children with different dialects may not get the same education, and some people may face barriers in politics.

`Any questions, please reach out!`

Chiawei Wang PhD\
Product Analyst\
<chiawei.w@outlook.com>
